{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import pickle\n",
    "import chromadb\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# Configuration\n",
    "CHROMA_DB_PATH = \"local_db_ollama/\"\n",
    "COOKBOOK_PATH = \"data/175_choice_recipes_mainly_furnished_by_members_of_the_chicago_womens_club-1887.pdf\"\n",
    "DICTIONARY_PATH = \"data/dictionary-of-food.pdf\"\n",
    "DICTIONARY_PICKLE_PATH = 'raw_dictionary_documents'\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    \"\"\"\n",
    "    Initialize the language model and embedding model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - llm (Ollama): The initialized language model.\n",
    "            - embed_model (HuggingFaceEmbedding): The initialized embedding model.\n",
    "    \"\"\"\n",
    "    llm = Ollama(model=\"llama3.1\")\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    Settings.llm = llm\n",
    "    Settings.embed_model = embed_model\n",
    "    return llm, embed_model\n",
    "\n",
    "llm, embed_model = initialize_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3:\n",
    "def load_dictionary_data(\n",
    "    pickle_path, pdf_path, use_pickle=True, llama_cloud_api_key=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Load dictionary data from a pickle file or generate it using LlamaParse.\n",
    "\n",
    "    Args:\n",
    "        pickle_path (str): The file path to the pickle file.\n",
    "        pdf_path (str): The file path to the PDF file.\n",
    "        use_pickle (bool, optional): Whether to use the pickled file. Defaults to True.\n",
    "        llama_cloud_api_key (str, optional): The API key for LlamaParse. Required if use_pickle is False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionary documents.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If use_pickle is False and llama_cloud_api_key is not provided.\n",
    "        FileNotFoundError: If the specified file does not exist.\n",
    "    \"\"\"\n",
    "    if use_pickle:\n",
    "        if not os.path.exists(pickle_path):\n",
    "            raise FileNotFoundError(f\"The pickle file {pickle_path} does not exist.\")\n",
    "        with open(pickle_path, \"rb\") as fp:\n",
    "            return pickle.load(fp)\n",
    "    else:\n",
    "        if not llama_cloud_api_key:\n",
    "            raise ValueError(\n",
    "                \"LlamaParse API key is required when not using pickle file.\"\n",
    "            )\n",
    "\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"The PDF file {pdf_path} does not exist.\")\n",
    "\n",
    "        parser = LlamaParse(api_key=llama_cloud_api_key, result_type=\"markdown\")\n",
    "        dictionary_docs = parser.load_data(pdf_path)\n",
    "\n",
    "        # Optionally, save the generated data as a pickle file for future use\n",
    "        with open(pickle_path, \"wb\") as fp:\n",
    "            pickle.dump(dictionary_docs, fp)\n",
    "\n",
    "        return dictionary_docs\n",
    "\n",
    "\n",
    "def load_cookbook_data(path):\n",
    "    \"\"\"\n",
    "    Load cookbook data from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of cookbook documents.\n",
    "    \"\"\"\n",
    "    return SimpleDirectoryReader(input_files=[path]).load_data()\n",
    "\n",
    "\n",
    "\n",
    "cookbook_docs = load_cookbook_data(COOKBOOK_PATH)\n",
    "dictionary_docs = load_dictionary_data(\n",
    "    DICTIONARY_PICKLE_PATH, DICTIONARY_PATH, use_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Create Vector Store and Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(db_path, collection_name):\n",
    "    \"\"\"\n",
    "    Create a vector store using ChromaDB.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): The path to the ChromaDB database.\n",
    "        collection_name (str): The name of the collection to create or get.\n",
    "\n",
    "    Returns:\n",
    "        StorageContext: A storage context object for the vector store.\n",
    "    \"\"\"\n",
    "    db = chromadb.PersistentClient(path=db_path)\n",
    "    chroma_collection = db.get_or_create_collection(collection_name)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    return StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "def create_index(documents, storage_context):\n",
    "    \"\"\"\n",
    "    Create a vector store index from documents.\n",
    "\n",
    "    Args:\n",
    "        documents (list): A list of documents to index.\n",
    "        storage_context (StorageContext): The storage context for the index.\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex: The created vector store index.\n",
    "    \"\"\"\n",
    "    return VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "storage_context = create_vector_store(CHROMA_DB_PATH, \"dictionary_food\")\n",
    "cookbook_index = create_index(cookbook_docs, storage_context)\n",
    "dictionary_index = create_index(dictionary_docs, storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Create Query Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine(index, similarity_top_k=3):\n",
    "    \"\"\"\n",
    "    Create a query engine from an index.\n",
    "\n",
    "    Args:\n",
    "        index (VectorStoreIndex): The index to create the query engine from.\n",
    "        similarity_top_k (int, optional): The number of top similar results to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        QueryEngine: The created query engine.\n",
    "    \"\"\"\n",
    "    return index.as_query_engine(similarity_top_k=similarity_top_k)\n",
    "\n",
    "cookbook_query_engine = create_query_engine(cookbook_index)\n",
    "dictionary_query_engine = create_query_engine(dictionary_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine_tools(cookbook_engine, dictionary_engine):\n",
    "    \"\"\"\n",
    "    Create query engine tools for the agent.\n",
    "\n",
    "    Args:\n",
    "        cookbook_engine (QueryEngine): The query engine for the cookbook.\n",
    "        dictionary_engine (QueryEngine): The query engine for the dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of QueryEngineTool objects.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        QueryEngineTool(\n",
    "            query_engine=cookbook_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"Food_Cookbook\",\n",
    "                description=\"Provides a collection of 175 choice recipes from the Chicago Women's Club in 1887.\",\n",
    "            ),\n",
    "        ),\n",
    "        QueryEngineTool(\n",
    "            query_engine=dictionary_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"Food_Dictionary\",\n",
    "                description=\"Provides definitions of words related to English cuisine and food industry terms.\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "def create_agent(query_engine_tools):\n",
    "    \"\"\"\n",
    "    Create an agent with the given query engine tools.\n",
    "\n",
    "    Args:\n",
    "        query_engine_tools (list): A list of QueryEngineTool objects.\n",
    "\n",
    "    Returns:\n",
    "        AgentRunner: The created agent runner.\n",
    "    \"\"\"\n",
    "    agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "        query_engine_tools,\n",
    "        verbose=False,\n",
    "        allow_parallel_tool_calls=False,\n",
    "    )\n",
    "    return AgentRunner(agent_worker)\n",
    "\n",
    "query_engine_tools = create_query_engine_tools(cookbook_query_engine, dictionary_query_engine)\n",
    "agent = create_agent(query_engine_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agent(agent, query):\n",
    "    \"\"\"\n",
    "    Query the agent with a given input.\n",
    "\n",
    "    Args:\n",
    "        agent (AgentRunner): The agent to query.\n",
    "        query (str): The query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The agent's response to the query.\n",
    "    \"\"\"\n",
    "    return agent.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is aloo?\n",
      "Response: The output from the ipython tool indicates that \"Aloo\" refers to potatoes in South Asian cuisine, particularly in India and other surrounding countries.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "response1 = query_agent(agent, \"What is aloo?\")\n",
    "print(\"Query: What is aloo?\")\n",
    "print(\"Response:\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: How to prepare Marrow Dumpling Soup?\n",
      "Response: The output from the ipython tool provides a detailed recipe for preparing Marrow Dumpling Soup. The steps are:\n",
      "\n",
      "1. Prepare small round dumplings from a mixture of grated French breakfast-roll crust, crumbled inside, milk-soaked breadcrumbs, chopped fine beef marrow, egg yolks, salt, and pepper.\n",
      "2. Boil three pints of stock in a large pot.\n",
      "3. Carefully drop the dumplings into the boiling liquid and let them cook for 20-30 minutes or until they're cooked through.\n",
      "4. Prepare the vegetables by cutting an equal quantity of carrots, turnips, and onions into small balls or squares.\n",
      "5. Boil these ingredients in water with a little salt until tender.\n",
      "6. Carefully remove the pieces of tail from the pot, strain the liquor, and skim off all the fat.\n",
      "7. Put the cooked vegetables back into the stewpan along with a pound of beef marrow, a teaspoonful of salt, and the prepared dumplings.\n",
      "8. Let everything simmer together for a while.\n",
      "9. Add a glass of port wine to give it an extra boost of flavor.\n",
      "\n",
      "These steps should be followed to prepare a delicious and hearty Marrow Dumpling Soup.\n"
     ]
    }
   ],
   "source": [
    "response2 = query_agent(agent, \"How to prepare Marrow Dumpling Soup? Give me steps.\",)\n",
    "print(\"\\nQuery: How to prepare Marrow Dumpling Soup?\")\n",
    "print(\"Response:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
